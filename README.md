College Information RAG Chatbot
A Retrieval-Augmented Generation (RAG) based chatbot designed to assist students with college-related queries, such as admissions, departments, courses, and campus life. Built using powerful open-source tools like Mistral-7B-Instruct, FAISS, LangChain, and Sentence Transformers.

Tech Stack
Programming Language: Python

Large Language Model: Mistral-7B-Instruct-v0.1-AWQ (quantized)

Semantic Search: FAISS + sentence-transformers/all-mpnet-base-v2

Frameworks & Libraries:

Hugging Face Transformers

LangChain

FAISS

Sentence Transformers

Document Processing: RecursiveCharacterTextSplitter, TextLoader

Deployment Ready With: FastAPI / Streamlit

Key Features
ğŸ’¬ Context-Aware Answering: Uses a fine-tuned Mistral-7B-Instruct LLM to answer student queries.

ğŸ” Semantic Search: Accurately retrieves relevant documents using FAISS and dense embeddings.

ğŸ§© Chunking with Context: Utilizes RecursiveCharacterTextSplitter to retain contextual integrity during document chunking.

ğŸ”„ Modular RAG Pipeline: Integrates embedding, vector search, and LLM via LangChainâ€™s RetrievalQA.

âš¡ Efficient Inference: Optimized quantized models ensure cost-efficient CPU-based deployment.

ğŸ—ï¸ Scalable Architecture: Backend-ready for deployment with FastAPI or Streamlit for interactive frontend experiences.

Project Structure
ğŸ“ rag-college-chatbot/
â”‚
â”œâ”€â”€ ğŸ“„ app.py                  # Backend FastAPI or Streamlit app
â”œâ”€â”€ ğŸ“„ rag_pipeline.py         # LangChain-based RAG pipeline
â”œâ”€â”€ ğŸ“„ vectorstore_builder.py  # FAISS vector store construction
â”œâ”€â”€ ğŸ“„ llm_loader.py           # Load and configure Mistral-7B
â”œâ”€â”€ ğŸ“„ requirements.txt        # Python dependencies
â”œâ”€â”€ ğŸ“ data/                   # Folder for raw and processed documents
â”œâ”€â”€ ğŸ“ models/                 # Folder to store quantized LLM models
â””â”€â”€ ğŸ“„ README.md               # Project documentation

Installation
# Clone the repo
git clone https://github.com/your-username/rag-college-chatbot.git
cd rag-college-chatbot

# (Optional) Create a virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt

Model Details
LLM: Mistral-7B-Instruct-v0.1-AWQ

Tokenizer: AutoTokenizer.from_pretrained()

Model Loader: AutoModelForCausalLM.from_pretrained() with quantized weights

Embeddings: all-mpnet-base-v2 from Sentence Transformers

Features in Detail
Feature	Description
Document Ingestion	TextLoader reads plain text files and prepares them for vectorization
Chunking	RecursiveCharacterTextSplitter maintains context across document chunks
Embeddings	Sentence-level embeddings for semantic similarity via all-mpnet-base-v2
Vector Store	Efficient FAISS index for fast nearest-neighbor search
LLM Inference	Mistral-7B-Instruct-v0.1-AWQ for generating responses
Retrieval QA Pipeline	Built using LangChainâ€™s RetrievalQA module
Modular Design	Easy to extend or swap out components
Deployment Ready	Designed for integration with FastAPI or Streamlit
